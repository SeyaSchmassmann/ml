{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FHNW Machine Learning - FS2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f78653ecc06fe764edbe1be8b81e8459",
     "grade": false,
     "grade_id": "setup",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT EDIT\n",
    "\n",
    "# Notebook configs\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c9cd741a8aecb1bd1be4419a8912abf8",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Bewertete Übung 03\n",
    "\n",
    "**Ausgabe:** Montag 20.05.2024\n",
    "\n",
    "**Abgabe:**  Montag 10.06.2024, 23:59 Uhr\n",
    "\n",
    "\n",
    "## Vorgaben zu Umsetzung und Abgabe\n",
    "\n",
    "- Die Algorithmen müssen auf der Basis von Array Operationen selber implementiert werden.\n",
    "- Der Code muss lauffähig sein bei Ausführung im Docker-Container zum Repo oder auf JHub. \n",
    "- Es darf kein Code ausgelagert werden, i.e. sämtlicher Code muss sich im Notebook befinden.\n",
    "- Sämtliche Plots sind komplett beschriftet (Achsen, Labels, Überschrift, Colorbar, ..), so dass der Plot ohne den Code zu konsultieren, verstanden werden kann.\n",
    "- Zu jedem Plot gehört eine kurze Diskussion, welche den Plot erklärt und die wichtigsten Einsichten, die damit sichtbar werden, festhält.  \n",
    "- Als **Abgabe** zählt der letzte Commit vor Abgabetermin in in Ihrem Fork des Repos.  \n",
    "\n",
    "- **Bitte löschen, duplizieren (splitten!) und verschieben Sie die vorhandenen Zellen nicht**. Dies führt zu Problemen bei der Korrektur. Sie dürfen aber beliebig viele weitere Zellen hinzufügen.\n",
    "- Laufzeit vom Notebook: Das Notebook sollte in weniger als 30 Minuten ausgeführt werden können.\n",
    "\n",
    "Für die Erarbeitung der Lösung darf unter Studierenden zusammengearbeitet werden. Die Zusammenarbeit ist dabei aber auf konzeptionelle und algorithmische Fragen und Verständnisaspekte beschränkt.  \n",
    "\n",
    "**Es darf kein Code oder Text von anderen oder vom Internet kopiert werden.**\n",
    "\n",
    "\n",
    "### Module\n",
    "\n",
    "Neben den Python-Basismodulen dürfen Sie die folgenden Module immer benutzen: `numpy`, `pandas`, `matplotlib`, `seaborn`,  `tqdm`.\n",
    "\n",
    "Sie dürfen auch generell [`sklearn.preprocessing`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing), [`sklearn.model_selection`](https://scikit-learn.org/stable/model_selection.html) und [`sklearn.compose`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.compose) benutzen.\n",
    "\n",
    "Zusätzliche Module dürfen Sie nur verwenden wenn ausdrücklich erwähnt oder bereits vorgegeben in der Code-Cell.\n",
    "\n",
    "## Bewertung\n",
    "\n",
    "Bewertet wird:\n",
    "\n",
    "- Vollständigkeit (Code, Text)\n",
    "- Korrektheit (Code, Text)\n",
    "- Implementation (z.B. Vektorisierung der Operationen, Scikit-Learn API, Visualisierungen, Lesbarkeit Code/Output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "87b67680f0c131cc9ed1bbfc7c8bdc0a",
     "grade": false,
     "grade_id": "einleitung",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Einleitung\n",
    "\n",
    "Daniele arbeitet bei einem grossen Schweizer TV-Anbieter und hat von Mika erfahren, dass Sie mit Machine-Learning echten Mehrwert liefern können. Daniele hat den Auftrag bekommen Film-Empfehlungen für Kunden zu erstellen, damit die Kunden bessere Vorschläge bekommen und das neue Streaming-Angebot nutzen. Das Management möchte, dass Daniele mit modernen Machine-Learning Ansätzen arbeitet und diese evaluiert. Insbesondere soll [_collaborative filtering_](https://en.wikipedia.org/wiki/Collaborative_filtering) ausprobiert werden, wobei Kunden mit ähnlichen Präferenzen gefunden werden um dann gemeinsam (_collaborative_) Empfehlungen generieren zu können. \n",
    "\n",
    "Das Modell soll in Echtzeit, also sobald neue _Ratings_ verfügbar sind, aktualisiert werden können. Deshalb hat man entschieden einen Ansatz zu wählen mit dem man mit _Stochastic Gradient Descent (SGD)_ das Modell mit einzelnen Beobachtungen anpassen (trainieren) kann. Das wäre auch in Echtzeit aktualisierbar.\n",
    "\n",
    "In einem ersten Schritt soll mit öffentlich verfügbaren Daten ein Modell erstellt und getestet werden um zu beurteilen, ob sich weitere Investments in Empfehlungssysteme lohnen. Sie sollen Daniele dabei unterstützen und auf dem bekannten [_MovieLens_](https://movielens.org/) Datensatz einen Prototyp erstellen.\n",
    "\n",
    "\n",
    "\n",
    "## Ziel\n",
    "\n",
    "Unser Ziel ist es zu beantworten ob es möglich ist sinnvolle Empfehlungen zu generieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8f46ec1c995142a2a2b7f9c94c129d65",
     "grade": false,
     "grade_id": "aufgabe1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Aufgabe 1 (8 Punkte)\n",
    "\n",
    "In dieser Aufgabe geht es darum die Daten einzulesen, kennenzulernen und für die Modellierung vorzubereiten.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8442eb2f167d02600a34755ac0f589ae",
     "grade": false,
     "grade_id": "task1a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 1a\n",
    "\n",
    "Lesen Sie die Datensätze `movies.csv` und `ratings.csv` ein.\n",
    "\n",
    "Charakterisieren Sie die Datensätze indem Sie folgende Aufgaben erledigten, bzw. Fragen beantworten. Nur die Beantwortung der folgenden Fragen wird bewertet:\n",
    "\n",
    "1. Beschreiben Sie die Datensätze kurz in Worten: Was ist jeweils der Inhalt und wie hängen die beiden Datensätze zusammen?\n",
    "2. Erstellen Sie die Rating-Matrix $R$ mit dem bereitgestellten Code `create_rating_matrix`. $R$ hat die Dimensionalität $R \\in \\mathbb{R}^{N_u  x N_i}$, wobei $N_u$ die Anzahl Users sind und $N_i$ die Anzahl Filme (Items). Der Eintrag $r_{u,i}$ indexiert das Rating von User $u$ für den Film $i$ in $R$. Verifizieren Sie, dass die Anzahl Zeilen und die Anzahl Spalten stimmen.\n",
    "3. Was ist die _Sparsity_ von $R$?\n",
    "4. Zeigen Sie anhand von $R$ die Verteilung über die Ratings und beschreiben Sie diese mit Worten.\n",
    "5. Zeigen Sie anhand von $R$ die Verteilung über jeweils die mittleren User- und die mittleren Movie Ratings.\n",
    "6. Welcher Film wurde am besten, welcher am schlechtesten bewertet?\n",
    "7. Untersuchen Sie den Zusammenhang von \"imdbRating\" / \"imdbVotes\" und den bereitgestellten Ratings in `ratings.csv`.\n",
    "8. Finden Sie je einen Film und einen User welche \"extrem\" sind (bzw. mögliche Anomalien sind). Sie können das selber, sinnvoll, definieren.\n",
    "\n",
    "\n",
    "Sie können die Fragen mit Code beantworten (mit Grafiken und/oder Print-Statements). Referenzieren Sie klar auf die Fragennummer. Beispiel:\n",
    "\n",
    "```\n",
    "print(\"1) Die Datensätze...\")\n",
    "print(f\"3) Die Sparsity beträgt: {sparsity:.3f}\")\n",
    "```\n",
    "\n",
    "Sie können auch eine zusätzliche Text-Zelle einfügen und Fragen so beantworten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c884d65a090b57518bd705ee60275c93",
     "grade": true,
     "grade_id": "answer1a",
     "locked": false,
     "points": 8,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def create_rating_matrix(df: pd.DataFrame) -> (np.ndarray, Dict[int, int], Dict[int, int]):\n",
    "    \"\"\"Create Ratings Matrix and Mapping Tables. \n",
    "        \n",
    "        Args:\n",
    "            df: pd.DataFrame with columns [movieId, userId, rating]\n",
    "    \n",
    "        Returns:\n",
    "                Ratings-Matrix (np.ndarray),\n",
    "                Column-No to Movie-ID Mapper (Dict[column_number, movieId]),\n",
    "                Row-No to User-ID Mapper (Dict[row_number, userId])\n",
    "\n",
    "        Remark:\n",
    "            Zero-Entries in Ratings-Matrix are missing / non-existing ratings\n",
    "    \"\"\"\n",
    "    # Mapping Tables\n",
    "    map_movie_to_id = {k:i for i, k in enumerate(df['movieId'].unique())}\n",
    "    map_user_to_id = {k:i for i, k in enumerate(df['userId'].unique())}\n",
    "    \n",
    "    map_col_id_to_movie = {v: k for k, v in map_movie_to_id.items()}\n",
    "    map_row_id_to_user_id = {v: k for k, v in map_user_to_id.items()}\n",
    "\n",
    "    mapped_user_id = df['userId'].map(map_user_to_id)\n",
    "    mapped_movie_id = df['movieId'].map(map_movie_to_id)\n",
    "    \n",
    "    # Create Ratings Matrix\n",
    "    from scipy.sparse import csc_matrix\n",
    "    ratings = csc_matrix(\n",
    "        (df['rating'], (mapped_user_id, mapped_movie_id)),\n",
    "        shape=(len(map_user_to_id.keys()), \n",
    "               len(map_movie_to_id.keys()))).toarray()\n",
    "\n",
    "    return ratings, map_col_id_to_movie, map_row_id_to_user_id\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "db35742e8ccfe60a64ef95eaf4d1cd22",
     "grade": false,
     "grade_id": "aufgabe2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Aufgabe 2 (21 Punkte)\n",
    "\n",
    "In dieser Aufgabe implementieren Sie einen Sklearn-Estimator um ein Modell der Daten zu fitten mit dem Empfehlungen generiert werden können.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "15926547d8594cb8884040d57e76a73e",
     "grade": false,
     "grade_id": "task2a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 2a\n",
    "\n",
    "Sie möchten eine Rating Matrix $R$ in zwei Matrizen $U \\in \\mathbb{R}^{N_u \\times K}$ (User-Faktoren) und $M \\in \\mathbb{R}^{N_i \\times K}$ (Movie-Faktoren) faktorisieren. Die Faktorisierung $\\hat{R}$ soll $R$ möglichst gut approximieren im Sinne des quadrierten Fehlers. $K$ sind die Anzahl Faktoren.\n",
    "\n",
    "Die Gleichung sieht folgendermassen aus und enthält zusätzlich noch Bias-Vektoren.\n",
    "\n",
    "\\begin{align}\n",
    "R \\approx \\hat{R} = UM^T + \\mathbf{b_u} + \\mathbf{b_m}^T + \\overline{r}\n",
    "\\end{align}\n",
    "\n",
    "$R$ hat die Dimensionalität $R \\in \\mathbb{R}^{N_u \\times N_i}$, wobei $N_u$ die Anzahl Users sind und $N_i$ die Anzahl Items. $\\mathbf{b}_u \\in \\mathbb{R}^{N_u}$ ist ein User-Bias Vektor, $\\mathbf{b}_m \\in \\mathbb{R}^{N_i}$ ein Item-Bias Vektor, und $\\overline{r}$ das globale Durchschnittsrating (die Bias-Vektoren müssen mit _broadcasting_ addiert werden). \n",
    "\n",
    "Die Hoffnung ist, dass $\\hat{R}$ dort wo $R$ keine Einträge hat (da die Matrix $R$ relativ sparse ist), realistische Einträge erzeugt, die für Empfehlungen genutzt werden können.\n",
    "\n",
    "Wir möchten den quadrierten Fehler zwischen $\\hat{R}$ und $R$ minimieren. Zusätzlich möchten wir mit einer Regularisierung ($\\Omega$) Overfitting verhindern. Dazu definieren wir folgende Kostenfunktion:\n",
    "\n",
    "\\begin{align}\n",
    "J(U, M, \\mathbf{b_u},\\mathbf{b_m}) &= \\frac{1}{| \\mathbb{Z} |} \\Big(\\sum_{u, i \\in \\mathbb{Z}} \\frac{1}{2}(r^{(u,i)} - \\hat{r}^{(u,i)})^2 + \\sum_{u, i \\in \\mathbb{Z}} \\Omega^{(u, i)} \\Big)\n",
    "\\end{align}\n",
    "\n",
    "Wobei:\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{r}^{(u,i)} &= \\mathbf{u}^{(u)T} \\mathbf{m}^{(i)} + b_u^{(u)} + b_m^{(i)} \\\\\n",
    "\\Omega^{(u, i)} &= \\frac{\\lambda}{2} \\Big( \\lVert \\mathbf{u}^{(u)} \\rVert^2_2 +  \\lVert \\mathbf{m}^{(i)} \\rVert^2_2 + b_u^{(u)2} + b_m^{(i)2} \\Big)\n",
    "\\end{align}\n",
    "\n",
    "$\\mathbb{Z}$ ist das Set der bekannten/nicht-null Einträge der Rating-Matrix $R$ (alle Kombinationen von $(u,r)$ die vorkommen). $\\mathbf{u}^{(u)T}$ ist der $u$-te Zeilenvektor von $U$ und $\\mathbf{m}^{(i)}$ der $i$-te Spaltenvektor von $M^T$. $\\lambda$ ist der Regularisierungsfaktor. Das globale Durchschnittsrating $\\overline{r}$ berechnen wir auf $R$ und ziehen das von allen Ratings ab. Wir führen die Optimisierung als auf $R_{\\text{center}} = R - \\overline{r}$ durch. Die quadrierte L-2 Norm ist folgendermassen definiert: $\\lVert \\mathbf{z} \\rVert^2_2 = \\sum_i (z^{(i)})^2$.\n",
    "\n",
    "### Optimisierung mit Stochastic Gradient Descent (SGD)\n",
    "\n",
    "Man optimiert die Kostenfunktion abwechselnd, mal für $\\mathbf{u}^{(u)T}$ und dann für $\\mathbf{m}^{(i)}$ (und die Biases), wobei man die andere Variable jeweils konstant hält. Das führt zu einem _least squares_ Optimisierungs-Problem. Mit _SGD_ approximiert man die Kostenfunktion (und deren Gradienten) mit einem per Sample-Loss $L$:\n",
    "\n",
    "Mit $M$ fix:\n",
    "\\begin{align}\n",
    "L(U, r^{(u,i)}) &= \\frac{1}{2} (r^{(u,i)} - \\hat{r}^{(u,i)})^2 + \\Omega^{(u, i)} \\\\\n",
    "J(U) &= \\mathbb{E}_{u,i \\sim \\mathbb{Z}} L(U, r^{(u,i)}) = \\frac{1}{| \\mathbb{Z} |} \\sum_{u, i \\in \\mathbb{Z}}  L(U, r^{(u,i)})\n",
    "\\end{align}\n",
    "\n",
    "Mit $U$ fix:\n",
    "\\begin{align}\n",
    "L(M, r^{(u,i)}) &= \\frac{1}{2} (r^{(u,i)} - \\hat{r}^{(u,i)})^2 + \\Omega^{(u, i)} \\\\\n",
    "J(M) &= \\mathbb{E}_{u,i \\sim \\mathbb{Z}} L(M, r^{(u,i)}) = \\frac{1}{| \\mathbb{Z} |} \\sum_{u, i \\in \\mathbb{Z}}  L(M, r^{(u,i)})\n",
    "\\end{align}\n",
    "\n",
    "### Algorithmus\n",
    "\n",
    "Wir optimieren die Kostenfunktion für jeden Eintrag in der Rating-Matrix $R$ mit folgendem Algorithmus. Wobei $\\eta$ die _learning rate_ ist und $t$ den Iterationschritt indexiert.\n",
    "\n",
    "For all $u, i \\in \\mathbb{Z}$ do:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{u}^{(u)}_{t+1} &= \\mathbf{u}^{(u)}_{t} - \\eta \\frac{\\partial L(U, r^{(u,i)})}{\\partial \\mathbf{u}^{(u)}_{t}} \\\\\n",
    "\\mathbf{m}^{(i)}_{t+1} &= \\mathbf{m}^{(i)}_{t} - \\eta \\frac{\\partial L(M, r^{(u,i)})}{\\partial \\mathbf{m}^{(i)}_{t}} \\\\\n",
    "b_{m, t+1}^{(i)} &= b_{m, t}^{(i)} - \\eta \\frac{\\partial L(U, r^{(u,i)})}{\\partial b_{m, t}^{(i)}} \\\\\n",
    "b_{u, t+1}^{(u)} &= b_{u, t}^{(u)} - \\eta \\frac{\\partial L(U, r^{(u,i)})}{\\partial b_{u, t}^{(u)}} \\\\\n",
    "\\end{align}\n",
    "\n",
    "Repeat until _max epochs_ is reached.\n",
    "\n",
    "### Implementation\n",
    "\n",
    "Ergänzen Sie die Klasse `SparseMatrixFactorization`.\n",
    "\n",
    "\n",
    "**Beachten Sie:**\n",
    "\n",
    "- In sklearn wird statt $\\lambda$ jeweils $\\alpha$ `alpha` als Bezeichnung für die Regularisierungsstärke verwendet (wohl weil `lambda` ein reserviertes Wort ist in Python).\n",
    "\n",
    "- Coursera verwendet für die Bezeichung der Anzahl Datenpunkte $m$. Hier verwenden wir $n$, was gebräuchlicher ist. Ausserdem: $w$ ist ein Skalar, $\\mathbf{w}$ ein Vektor und $\\mathbf{W}$ eine Matrix.\n",
    "\n",
    "- Implementieren Sie alles vektorisiert.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fab6e7c135c8c28d223b3604f53b0d94",
     "grade": true,
     "grade_id": "answer2a",
     "locked": false,
     "points": 15,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Self\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "class SparseMatrixFactorization(BaseEstimator):\n",
    "    \"\"\" Sparse Matrix Factorization with Stochastic Gradient Descent \"\"\"\n",
    "    def __init__(self, alpha: float, lr: float, num_components: int, num_epochs: int, random_seed: int=123):\n",
    "        \"\"\"\n",
    "            Args:\n",
    "                alpha: regularization constant\n",
    "                lr: learning rate constant\n",
    "                num_components: dimensionaliy of each user / item vector\n",
    "                num_epochs: number of passes over each entry in the Rating matrix\n",
    "                random_seed: random seed for reproducibility\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "        self.lr = lr\n",
    "        self.num_components = num_components\n",
    "        self.num_epochs = num_epochs\n",
    "        self.random_seed = random_seed\n",
    "    \n",
    "    def _initialize(self, X: np.ndarray) -> None:\n",
    "        \"\"\"Initiaizes user and item weights and biases.\n",
    "        \n",
    "            Args:\n",
    "                X (num_users, num_items) - The Rating Matrix\n",
    "    \n",
    "            Returns:\n",
    "                None\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    \n",
    "    def fit(self, X: np.ndarray) -> Self:\n",
    "        \"\"\"Fit the model.\n",
    "        \n",
    "            Args:\n",
    "                X (num_users, num_items) - The Rating Matrix\n",
    "    \n",
    "            Returns:\n",
    "                Self\n",
    "        \"\"\"\n",
    "        self._initialize(X)\n",
    "        self.epoch_end_cost_ = list()\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def take_one_step(self, X: np.ndarray, rating: (int, int)) -> None:\n",
    "        \"\"\"Take one gradient descent step for a specific item/user weight.\n",
    "    \n",
    "            Args:\n",
    "                X (num_users, num_items) - The Rating Matrix\n",
    "                rating (row_idx, column_idx) - Rating coordinates specified via\n",
    "                    User (row-index) and Item (column-index) for which to \n",
    "                    calculate the gradient for\n",
    "\n",
    "            Returns:\n",
    "                None\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "   \n",
    "    def calc_gradients(\n",
    "            self,\n",
    "            error: float,\n",
    "            m_item: np.ndarray,\n",
    "            u_user: np.ndarray,\n",
    "            bias_user: float,\n",
    "            bias_item: float) -> (float, float, float, float):\n",
    "        \"\"\" Calculate Gradients\n",
    "            Args:\n",
    "                error: for a single rating entry\n",
    "                m_item: weights of a single item [num_components]\n",
    "                u_user: weights of a single user [num_components]\n",
    "                bias_user: bias of a single user (scalar)\n",
    "                bias_item: bias of a single item (scalar)\n",
    "            Returns:\n",
    "                Tuple (dJ_dUser, dJ_dItem, dJ_dUserBias, dJ_dItemBias)\n",
    "                \n",
    "                with shapes:\n",
    "                \n",
    "                ([num_components], [num_components], float, float)\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def predict(self) -> np.ndarray:\n",
    "        \"\"\" Calculate Approximation of Rating Matrix\n",
    "            Returns:\n",
    "                Approximation of Rating Matrix [num_users, num_items]\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def score(self, X: np.ndarray) -> float:\n",
    "        \"\"\" Mean Squared Error between X and Approximation\n",
    "            Args:\n",
    "                X: Ratings Matrix [num_users, num_items]\n",
    "            Returns:\n",
    "                MSE (float)\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def score_mae(self, X: np.ndarray) -> float:\n",
    "        \"\"\" Mean Absolute Error between X and Approximation\n",
    "            Args:\n",
    "                X: Ratings Matrix [num_users, num_items]\n",
    "            Returns:\n",
    "                MAE (float)\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def calc_cost(self, y_true: np.ndarray, y_pred: np.ndarray) -> (float, float, float):\n",
    "        \"\"\" Cost function\n",
    "            Args:\n",
    "                y_true: Ratings Matrix [num_users, num_items]\n",
    "                y_pred: Predicted Ratings Matrix [num_users, num_items]\n",
    "            Returns:\n",
    "                Tuple with (total cost, squared_error_cost, regularization_cost)\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bc024570c90641c17256ac59a0348ba8",
     "grade": false,
     "grade_id": "task2b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Aufgabe 2b\n",
    "Die folgende Zelle enthält verschiedene Tests die Ihre Implementation prüfen. Sorgen Sie dafür, dass die folgenden Tests erfolgreich sind. Stellen Sie sicher, dass die Input-Shapes der Methoden die Sie implementieren den Doc-Strings entsprechen.\n",
    "\n",
    "**Achtung: Die Tests sind sehr simpel. Sie können also nicht davon ausgehen, dass Ihre Implementation korrekt ist sobald die Tests erfolgreich sind.**\n",
    "\n",
    "Ihre Abgabe wird noch mit weiteren, für Sie nicht sichtbare Tests, geprüft. Es ist grundsätzlich ihre Aufgabe, die Implementation genau zu prüfen. Sie können dazu weitere Zellen mit eigenen Tests einfügen. Sie können jedoch die folgende Zelle nicht ändern. Diese wird nach Abgabe wieder überschrieben, sodass die von mir definierten Tests ausgeführt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b44cb3dbdb570a5db515630f776f50d",
     "grade": true,
     "grade_id": "auto2b",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def print_result(test_name, passed, expected, actual):\n",
    "    status = \"Passed\" if passed else \"Failed\"\n",
    "    print(f\"{status} test: {test_name}\")\n",
    "    print(f\"----> Expected: {expected}\")\n",
    "    print(f\"----> Actual: {actual}\")\n",
    "\n",
    "def test_ones_matrix():\n",
    "    # Create a ones matrix\n",
    "    X = np.ones((5, 5))\n",
    "    \n",
    "    # Initialize the model\n",
    "    model = SparseMatrixFactorization(alpha=0, lr=0.01, num_components=2, num_epochs=50, random_seed=123)\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict()\n",
    "    \n",
    "    try:\n",
    "        np.testing.assert_allclose(predictions, 1, atol=0.1)\n",
    "        print_result(\"test_ones_matrix\", True, np.ones((5, 5)), predictions)\n",
    "    except AssertionError as e:\n",
    "        print_result(\"test_ones_matrix\", False, np.ones((5, 5)), predictions)\n",
    "\n",
    "\n",
    "def test_twos_matrix():\n",
    "    X = np.ones((5, 5)) + 1\n",
    "    \n",
    "    # Initialize the model\n",
    "    model = SparseMatrixFactorization(alpha=0, lr=0.01, num_components=2, num_epochs=50, random_seed=123)\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict()\n",
    "    \n",
    "    try:\n",
    "        np.testing.assert_allclose(predictions, 2, atol=0.1)\n",
    "        print_result(\"test_twos_matrix\", True, np.ones((5, 5)) + 1, predictions)\n",
    "    except AssertionError as e:\n",
    "        print_result(\"test_twos_matrix\", False, np.ones((5, 5)) + 1, predictions)\n",
    "\n",
    "\n",
    "def test_random_matrix():\n",
    "    X = np.array([\n",
    "        [4, 1, 4, 2],\n",
    "        [3, 5, 2, 2],\n",
    "        [2, 3, 1, 4],\n",
    "        [2, 3, 2, 2]\n",
    "    ])\n",
    "    \n",
    "    # Initialize the model\n",
    "    model = SparseMatrixFactorization(alpha=0, lr=0.1, num_components=4, num_epochs=100, random_seed=123)\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict()\n",
    "    \n",
    "    # The predictions should be close to the input, since there are no missing (zero) entries\n",
    "    try:\n",
    "        np.testing.assert_allclose(predictions, X, atol=0.1)\n",
    "        print_result(\"test_random_matrix\", True, X, predictions)\n",
    "    except AssertionError as e:\n",
    "        print_result(\"test_random_matrix\", False, X, predictions)\n",
    "\n",
    "        \n",
    "def test_sparse_matrix():\n",
    "    # Create a 5x6 matrix with random values and some zeros\n",
    "    X = np.array([\n",
    "        [5, 3, 0, 1, 2, 0],\n",
    "        [4, 0, 3, 0, 0, 2],\n",
    "        [0, 1, 5, 0, 3, 4],\n",
    "        [2, 0, 0, 4, 1, 0],\n",
    "        [0, 4, 2, 0, 0, 5]\n",
    "    ])\n",
    "    \n",
    "    # Initialize the model\n",
    "    model = SparseMatrixFactorization(alpha=0, lr=0.1, num_components=4, num_epochs=100, random_seed=123)\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict()\n",
    "    \n",
    "    try:\n",
    "        # Check that non-zero entries are close to the input values\n",
    "        non_zero_indices = np.nonzero(X)\n",
    "        np.testing.assert_allclose(predictions[non_zero_indices], X[non_zero_indices], atol=1.0)\n",
    "        print_result(\"test_sparse_matrix\", True, X[non_zero_indices], predictions[non_zero_indices])\n",
    "    except:\n",
    "        print_result(\"test_sparse_matrix\", False, X[non_zero_indices], predictions[non_zero_indices])\n",
    "    \n",
    "    try:\n",
    "        # Check that zero entries in the original matrix are now non-zero in the predictions\n",
    "        zero_indices = np.where(X == 0)\n",
    "        assert np.all(predictions[zero_indices] >= 0.0)\n",
    "        print_result(\"test_sparse_matrix\", True, \"all larger than 0.0\" , predictions[zero_indices])\n",
    "    except AssertionError as e:\n",
    "        print_result(\"test_sparse_matrix\", False, \"all larger than 0.0\", predictions[zero_indices])\n",
    "\n",
    "\n",
    "for test in [test_ones_matrix, test_twos_matrix, test_random_matrix, test_sparse_matrix]:\n",
    "    try:\n",
    "        test()\n",
    "    except Exception as e:\n",
    "        print(f\"Error during testing - test: {test} error: {e}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3ad79676108b2812fbfd64782cd18b5e",
     "grade": false,
     "grade_id": "task2c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Aufgabe 2c\n",
    "\n",
    "Trainieren Sie nun drei Modelle auf dem ganzen Datenset, berechnen und geben Sie jeweils `mean squared error` und `mean absolute error` aus. Plotten Sie Total-Loss, Squared-Error-Loss und Regularisierungs-Loss pro Epoche in eine Grafik für jedes Modell. \n",
    "\n",
    "\n",
    "Verwenden Sie folgende Hyper-Parameter für Modell 1:\n",
    "\n",
    "- $\\lambda$: 1e-4\n",
    "- $\\eta$: 0.01\n",
    "- $K$: 5\n",
    "- `num_epochs`: 40\n",
    "\n",
    "\n",
    "Verwenden Sie folgende Hyper-Parameter für Modell 2:\n",
    "\n",
    "- $\\lambda$: 1e-4\n",
    "- $\\eta$: 0.01\n",
    "- $K$: 10\n",
    "- `num_epochs`: 40\n",
    "\n",
    "Verwenden Sie folgende Hyper-Parameter für Modell 3:\n",
    "\n",
    "- $\\lambda$: 1e-3\n",
    "- $\\eta$: 0.01\n",
    "- $K$: 5\n",
    "- `num_epochs`: 40\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "314246ba5b9f17d59a9a4fd6a0dd45ad",
     "grade": true,
     "grade_id": "answer2c",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "params = [\n",
    "    {\"alpha\": 1e-4, \"lr\": 0.01, \"num_components\": 5, \"num_epochs\": 40},\n",
    "    {\"alpha\": 1e-4, \"lr\": 0.01, \"num_components\": 10, \"num_epochs\": 40},\n",
    "    {\"alpha\": 1e-3, \"lr\": 0.01, \"num_components\": 5, \"num_epochs\": 40},\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, figsize=(8, 12))   \n",
    "\n",
    "for i, param in enumerate(params):\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "plt.tight_layout()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "184e43fc07f4b928a4da8e442ae792d1",
     "grade": false,
     "grade_id": "task2d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Aufgabe 2d\n",
    "\n",
    "Diskutieren Sie die Grafiken. Interpretieren Sie die Unterschiede bezüglich der unterschiedlichen Hyper-Parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "edc530b166d66b680c1f3a71927ba9e3",
     "grade": true,
     "grade_id": "answer2d",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a06478e89bb74cdae20ef08fb4b6e02d",
     "grade": false,
     "grade_id": "aufgabe3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Aufgabe 3 (6 Punkte)\n",
    "\n",
    "In dieser Aufgabe versuchen wir ein möglichst gutes Modell zu finden.\n",
    "\n",
    "\n",
    "Sie werden dazu einen zufällig generierten Train-Test Split erstellen. Dabei soll immer genau ein zufällig ausgewähltes Rating pro User dem Test-Split zugeordnet werden, wobei die anderen Ratings dieses Users im Train-Split bleiben. Verwenden Sie dazu die Funktion `leave_one_out_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f12e95e42e22b5721af0a2e00851434a",
     "grade": false,
     "grade_id": "aufgabe3_code",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def leave_one_out_split(X: np.ndarray, random_seed=123) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Split dataset by randomly assigning one element of each row to test, the others to train.\n",
    "    \n",
    "        Args:\n",
    "            X: Ratings-Matrix [num_users, num_items]\n",
    "            random_seed: for reproducibility\n",
    "\n",
    "        Returns:\n",
    "            Tuple(Xtrain [num_users, num_items], Xtest[num_users, num_items])\n",
    "    \"\"\"\n",
    "    X_test = np.zeros_like(X)\n",
    "    X_train = X.copy()\n",
    "    \n",
    "    random_state = np.random.RandomState(random_seed)\n",
    "\n",
    "    for user_row in range(X.shape[0]):\n",
    "        non_zero = X[user_row, :].nonzero()[0]\n",
    "        item_col = random_state.choice(non_zero)\n",
    "        X_test[user_row, item_col] = X[user_row, item_col]\n",
    "        X_train[user_row, item_col] = 0\n",
    "\n",
    "    return X_train, X_test\n",
    "\n",
    "# X_train, X_test = leave_one_out_split(ratings)\n",
    "\n",
    "# assert np.bincount(X_test.nonzero()[0]).max() == 1, \\\n",
    "#     \"Each row (user) must have exactly 1 non-zero rating\"\n",
    "\n",
    "# assert all((ratings > 0).sum(axis=1) - (X_train > 0).sum(axis=1)) == 1, \\\n",
    "#     \"Each user has exactly one rating less in the training set as compared to the full set\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "95afc66613c80e38927671897a70017d",
     "grade": false,
     "grade_id": "task3a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Aufgabe 3a\n",
    "\n",
    "Vergleichen Sie mehrere Hyper-Parameter miteinander. Selektieren Sie das beste Modell gemäss _Mean Absolute Error_ (MAE) mit einem geeigneten Verfahren. Verwenden Sie dazu die Funktion `leave_one_out_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6844377f4868b8e2b8214c7664212893",
     "grade": true,
     "grade_id": "answer3a",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "08a702ada4bfcd523fd8f50729b1ec7f",
     "grade": false,
     "grade_id": "aufgabe4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Aufgabe 4 (5 Punkte)\n",
    "\n",
    "In dieser Aufgabe versuchen wir die Qualität der Recommendations qualitativ zu beurteilen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1436576d746c56570c66011c40035998",
     "grade": false,
     "grade_id": "task4a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 4a\n",
    "\n",
    "Erstellen Sie Empfehlungen (z.B. Top-5 predicted Ratings) für die ersten 3 User in der Ratings-Matrix mit ihrem besten Modell und versuchen Sie die Empfehlungen ganz grob qualitativ zu beurteilen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8d3f2da62ef33f39af3dd155be1121b",
     "grade": true,
     "grade_id": "answer4a",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "063930bb6d096157abce163e8c6070a3",
     "grade": false,
     "grade_id": "task4b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Aufgabe 4b\n",
    "\n",
    "Was halten Sie von den Empfehlungen? Was ist ihr Gesamteindruck vom Projekt? Geben Sie Daniele Feedback zu ihren Erkenntnissen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e9f94662cd7dc59b02d9ef9bc8748465",
     "grade": true,
     "grade_id": "answer4b",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
