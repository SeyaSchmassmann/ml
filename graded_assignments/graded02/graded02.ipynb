{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FHNW Machine Learning - FS2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e93cfa0ad0f1b289da520c9c0566a3b",
     "grade": false,
     "grade_id": "setup",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT EDIT THIS CELL\n",
    "# ADD IMOPRTS IN ASSIGNMENT CELLS\n",
    "\n",
    "# Notebook configs\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from IPython.display import HTML\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7c3e539a8fdaf2bf782ec314c792cecc",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Bewertete Übung 02\n",
    "\n",
    "**Ausgabe:** Montag, 15. April 2024\n",
    "\n",
    "**Abgabe:** Montag, 6. Mai 2024, 23:59 Uhr\n",
    "\n",
    "\n",
    "## Vorgaben zu Umsetzung und Abgabe\n",
    "\n",
    "- Die Algorithmen müssen auf der Basis von Array Operationen selber implementiert werden.\n",
    "- Der Code muss lauffähig sein bei Ausführung im Docker-Container zum Repo oder auf JHub. \n",
    "- Es darf kein Code ausgelagert werden, i.e. sämtlicher Code muss sich im Notebook befinden.\n",
    "- Sämtliche Plots sind komplett beschriftet (Achsen, Labels, Überschrift, Colorbar, ..), so dass der Plot ohne den Code zu konsultieren, verstanden werden kann.\n",
    "- Als **Abgabe** zählt der letzte Commit vor Abgabetermin in in Ihrem Fork des Repos.  \n",
    "\n",
    "- **Bitte löschen, kopieren, duplizieren, splitten und verschieben Sie die vorhandenen Zellen nicht**. Dies führt zu Problemen bei der Korrektur. Sie dürfen aber beliebig viele weitere Zellen hinzufügen (nur via **insert new cell**).\n",
    "- Laufzeit vom Notebook: Das Notebook sollte in weniger als 30 Minuten ausgeführt werden können.\n",
    "\n",
    "Für die Erarbeitung der Lösung darf unter Studierenden zusammengearbeitet werden. Die Zusammenarbeit ist dabei aber auf konzeptionelle und algorithmische Fragen und Verständnisaspekte beschränkt.  \n",
    "\n",
    "**Es darf kein Code oder Text von anderen oder vom Internet kopiert werden.**\n",
    "\n",
    "\n",
    "### Module\n",
    "\n",
    "Neben den Python-Basismodulen dürfen Sie die folgenden Module immer benutzen: `numpy`, `pandas`, `matplotlib`, `seaborn`,  `tqdm` (für Progress-Bars).\n",
    "\n",
    "Sie dürfen auch generell [sklearn.preprocessing](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing), [sklearn.model_selection](https://scikit-learn.org/stable/model_selection.html), [sklearn.pipeline](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.pipeline) und [sklearn.compose](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.compose) benutzen.\n",
    "\n",
    "Zusätzliche Module dürfen Sie nur verwenden wenn ausdrücklich erwähnt oder bereits vorgegeben in der Code-Cell.\n",
    "\n",
    "## Bewertung\n",
    "\n",
    "Bewertet wird:\n",
    "\n",
    "- Vollständigkeit (Code, Text)\n",
    "- Korrektheit (Code, Text)\n",
    "- Implementation (z.B. Vektorisierung der Operationen, Scikit-Learn API, Visualisierungen, Lesbarkeit Code/Output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "10c97ee3402e1f485102efcac36ad872",
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Einleitung\n",
    "\n",
    "Mika arbeitet für eine Hotelkette welche mit schlecht ausgelasteten Hotels zu kämpfen hat. In einer Datenanalyse hat man festgestellt, dass ein wichtiger Grund für die schlechte Auslastung, stornierte Buchungen sind. Diese Buchungen werden zum Teil auch kurzfristig storniert und können dann oft nicht mehr mit neuen Gästen kompensiert werden. Das Management des Hotels möchte nun herausfinden, ob es möglich ist vorherzusagen, welche Buchungen storniert werden. Mika hat nun die Aufgabe bekommen ein Modell zu erstellen, um für jede Buchung eine Vorhersage zu erstellen. Mika hat von zwei Hotels Datensätze gesammelt und diese aufbereitet. Mika hat von Alex erfahren, dass Sie ein Experte in Sachen Machine Learning sind und bittet Sie um Hilfe.\n",
    "\n",
    "Es ist das Ziel aus Buchungsdaten (siehe Tabelle unten) vorherzusagen, ob diese storniert wird `IstStorniert`.\n",
    "\n",
    "\n",
    "| Spalt                  | Beschreibung |\n",
    "|---------------------------------|----------------|\n",
    "| DurchschnittlicherTagespreis    | Durchschnittlicher Preis pro Nacht |\n",
    "| Erwachsene                      | Anzahl der Erwachsenen |\n",
    "| Ankunftsmonat                   | Monat der Ankunft |\n",
    "| Babys                           | Anzahl der Babys |\n",
    "| Kinder                          | Anzahl der Kinder |\n",
    "| Anzahlungstyp                   | Typ der Anzahlung |\n",
    "| IstStorniert                    | Ob die Buchung storniert wurde (0=Nein, 1=Ja) |\n",
    "| IstWiederholungsgast            | Ob der Gast ein Wiederholungsgast ist |\n",
    "| Vorlaufzeit                     | Tage zwischen Buchung und Ankunft |\n",
    "| Marktsegment                    | Marktsegment der Buchung |\n",
    "| Mahlzeittyp                     | Gebuchter Mahlzeitentyp |\n",
    "| VorherigeNichtStornierteBuchungen | Anzahl vorheriger nicht stornierter Buchungen |\n",
    "| VorherigeStornierungen          | Anzahl vorheriger Stornierungen |\n",
    "| BenötigteParkplätze             | Anzahl benötigter Parkplätze |\n",
    "| ReservierterZimmertyp           | Typ des reservierten Zimmers |\n",
    "| AufenthalteAnWochenendnächten   | Anzahl der Übernachtungen am Wochenende |\n",
    "| AufenthalteAnWochennächten      | Anzahl der Übernachtungen unter der Woche |\n",
    "| GesamtzahlDerSonderwünsche      | Anzahl der Sonderwünsche |\n",
    "| Hotel | ID vom Hotel für welches die Buchung gemacht worden ist\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6e468e9efb63d25d0131c14c10bd7787",
     "grade": false,
     "grade_id": "aufgabe1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Aufgabe 1 (5 Punkte)\n",
    "\n",
    "In dieser Aufgabe ist es das Ziel den Datensatz `./hotel_train.csv` einzulesen, kennenzulernen und erste Erkenntnisse zu diskutieren.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e244d8c99add69738fb34f06a5d0793b",
     "grade": false,
     "grade_id": "task1a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Charakterisieren Sie den Datensatz indem Sie folgende Aufgaben erledigten, bzw. Fragen beantworten. Nur die Beantwortung der folgenden Fragen wird bewertet:\n",
    "\n",
    "1. Wie beeinflusst die Anzahl und die Kategorien der Personen, die eine Buchung umfasst, die Zielvariable `IstStorniert`?\n",
    "2. Ist der Preis pro Nacht Abhängig von den Anzahl Personen?\n",
    "3. Schauen Sie sich die Wiederholungsgäste an: Wieviele gibt es und wie häufig stornieren diese im Vergleich zu den anderen Gästen?\n",
    "4. Von wievielen Hotels stammen die Buchungen? Was könnte das für einen Einfluss haben auf die Modellierung?\n",
    "5. Unser Ziel ist es den Buchungsstatus `IstStorniert` vorherzusagen unter Verwendung der anderen Variablen.  Was lässt sich über dieses Vorhaben sagen? Diskutieren Sie Ihre Einsichten.\n",
    "\n",
    "Beantworten Sie alle Fragen in der folgenden Text-Zelle. Referenzieren Sie die Fragen anhand der Fragennummer. Sie können auf Grafiken oder Tabellen referenzieren, die Sie unten in der Code-Zelle erstellen können.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "365da429b2d53ee3c6678f0fe7d2fa10",
     "grade": true,
     "grade_id": "answer1a",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0283dabcebe50e1996695950d091b2a9",
     "grade": false,
     "grade_id": "task1b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Erstellen Sie bei Bedarf Grafiken / Outputs um Fragen zu beantworten in der folgenden Zelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e8f87a91263d178ab1b6072bc6811b0",
     "grade": true,
     "grade_id": "answer1b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "db517ae0dab62c41b57c501bbfed2526",
     "grade": false,
     "grade_id": "aufgabe2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Aufgabe 2 (23 Punkte)\n",
    "\n",
    "Implementieren Sie einen _Random Forest Classifier_ basierend auf binären _Decision Trees_. Folgende Eigenschaften sollen vorhanden sein:\n",
    "\n",
    "- Man soll ein binäres Klassifikationsproblem modellieren können ($y \\in [0, 1]$).\n",
    "\n",
    "- Konfigurierbarkeit bezüglich vorgegebenen Parametern wie Abbruchkriterien (Regularisierung).\n",
    "\n",
    "- Korrektes bzw. sinnvolles Handling von verschiedenen Aspekten wie z.B. das Verhindern von leeren _Leaf Nodes_.\n",
    "\n",
    "- Modulare Implementation: Erstellen / Ergänzen Sie die bereitgestellten Klassen. Sie können auch neue Methoden oder Argumente hinzufügen.\n",
    "\n",
    "- Reproduzierbarkeit: Setzen Sie _random seeds_ wo nötig [siehe numpy](https://numpy.org/doc/stable/reference/random/index.html#random-quick-start).\n",
    "- score() soll die Accuracy berechnen.\n",
    "\n",
    "- Konsultieren Sie die Unterrichtsunterlagen, insbesondere für die Berechnung / das Finden der optimalen Splits.\n",
    "\n",
    "- Die Implementation benötigt viele Loops und lässt sich nicht gut vektorisieren.\n",
    "\n",
    "- Implementieren Sie das Modell gemäss sklearn-API.\n",
    "\n",
    "Im folgenden einige Hinweise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3cc5d3237371c32aa5ad555a02630b0d",
     "grade": false,
     "grade_id": "aufgabe2intro1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Die Vorgaben der Implementation sind sehr nahe an dem was in den Kursunterlagen gezeigt wird. Konsultieren Sie diese bei Bedarf.\n",
    "\n",
    "### Decision Tree\n",
    "\n",
    "Der Random Forest Classifier besteht aus einem _Ensemble_ von _Decision Tree Classifiern_. Die wichtigsten Funktionalitäten werden also in erstern Linie in der Klasse `BinaryDecisionTreeClassifier` implementiert sein. Die `BinaryRandomForestClassifier` Klasse managt das Training und das Ausführen von _Decision Trees_. \n",
    "\n",
    "Sie sollen einen `BinaryDecisionTreeClassifier` implementieren, der ausschliesslich binäre Splits auf nummerischen Variablen durchführt (das beinhaltet auch kategorielle Variablen die entsprechend _pre-processed_ worden sind). Ein solcher Decision Tree ist folgendermassen aufgebaut:\n",
    "\n",
    "![Binärer Decision Tree](decision_tree.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b6c808b83eb9b5a0dadc3fec031328b9",
     "grade": false,
     "grade_id": "aufgabe2intro2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Random Forest\n",
    "\n",
    "Ein Random Forest ist eine Kollektion von Decision Trees. Wobe jeder Decision Tree auf einem Trainingsdatensatz trainiert wird welcher mit _Resampling with Replacement_ erstellt worden ist.\n",
    "\n",
    "Ein Random Forest funktioniert also im wesentliche so:\n",
    "\n",
    "```\n",
    "def fit(self, X, y):\n",
    "    my_trees = list()\n",
    "    for i in num_trees:\n",
    "        X_sample, y_sample = sample_with_replacement(X, y)\n",
    "        dt = DecisionTreeClassifier(x_sample, y_sample)\n",
    "        my_trees.append(df.fit())\n",
    "```\n",
    "\n",
    "Zusätzlich werden bei jedem Node von einem Decision Tree nur ein zufälliges Sample von $l \\le k$ Features berücksichtigt (statt alle $k$ Features zu berücksichtigen).\n",
    "\n",
    "```\n",
    "def fit(self, X, y):\n",
    "    ...\n",
    "\n",
    "    node_features = sample(l, all_features)\n",
    "\n",
    "    best_feature = find_best_feature(node_features)\n",
    "    \n",
    "    ...\n",
    "```\n",
    "\n",
    "Um Predictions zu generieren werden alle Decision Trees konsultiert. Dabei wird die Klasse mit den meisten Stimmen (_Majority Vote_) als Vorhersage verwendet. Diese wird dann dem Datenpunkt zugeordnet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5175ff11584c904edecb0ca3d13ca2ba",
     "grade": false,
     "grade_id": "aufgabe2intro3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Building a Decision Tree\n",
    "\n",
    "Ein Decision Tree wird rekursiv erstellt. Man erstellt als erstes den Root-Node und splittet diesen dann. Dabei wird die gleiche Logik rekursiv auf alle Child-Nodes angewendet, bis ein Stop-Kriterium erreicht worden ist. \n",
    "\n",
    "Man sucht für jeden Node den optimalen Split $S_{j,t}$. Dieser ist definiert durch welches Feature $j$ bei welchem Threshold $t$ der Datenatz im entsprechenden Node (binär) gesplittet wird.\n",
    "\n",
    "#### Impurity\n",
    "\n",
    "Man möchte, dass die Nodes von einem Decision Tree möglichst uniform sind (tiefe _Impurity_ haben), d.h. möglichst aus Datenpunkten von einer Klasse bestehen. Man minimiert dazu eine Impurity Metrik $Q$ . Wir verwenden dabei die (binäre) Entropie $H$.\n",
    "\n",
    "#### Binäre Entropy\n",
    "\n",
    "Die binäre Entropy von einem Node kann man folgendermassen berechnen:\n",
    "\n",
    "\\begin{align}\n",
    "H(p) = -p \\log_2(p) - (1 - p) \\log_2(1 - p)\n",
    "\\end{align}\n",
    "\n",
    "Dabei entsprich $p$ dem Anteil der positiven Klasse (Anteil Datenpunkte mit $y=1$)\n",
    "\n",
    "Man kann leicht verifizieren, dass die binäre Entropie minimal wird wenn alle Datenpunkte von derselben Klasse sind (Achtung: $p\\log_2(p)=0$ falls $p=0$.)\n",
    "\n",
    "\n",
    "\n",
    "#### Information Gain\n",
    "\n",
    "Ganz spezifisch möchte man _Information Gain_ $IG$ optimieren. Das ist die Differenz in der _Impurity_ $Q$ bevor und nach einem Split.\n",
    "\n",
    "Formal wird der Information Gain für einen Split $S_{j,t}$ auf einem Datensatz $\\mathbf{X}$ berechnet als:\n",
    "\n",
    "\\begin{equation*}\n",
    "IG(\\mathbf{X}, S_{j,t}) = Q(\\mathbf{X}) - \\Big( \\frac{|\\mathbf{X}_{l}|}{|\\mathbf{X}|} Q(\\mathbf{X}_l) + \\frac{|D_{r}|}{|\\mathbf{X}|}  Q(\\mathbf{X}_r) \\Big)\n",
    "\\end{equation*}\n",
    "\n",
    "Dabei löst man an jedem Node das Optimisierungsproblem:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\operatorname*{argmax}_{j,t} IG(\\mathbf{X}, S_{j,t})\n",
    "\\end{equation*}\n",
    "\n",
    "Die _Impurity_ wird also noch gewichtet mit den Anzahl Beobachtungen in den Child-Nodes. Bei binären Splits gibt es immer genau zwei Child-nodes, einen linken $\\mathbf{X}_l$ und einen rechten $\\mathbf{X}_r$.\n",
    "\n",
    "\n",
    "#### Stopping Criteria\n",
    "\n",
    "Man stoppt den rekursiven Algorithmus und erstellt ein _Leaf Node_ wenn eine der folgende Bedingungen eintreffen:\n",
    "\n",
    "- Man hat eine vordefinierte maximale Tiefe erreicht (wobei der Root-Node auf Tiefe 0 ist).\n",
    "- Alle Beobachtungen in $\\mathbf{X}$ sind von derselben Klasse.\n",
    "- $\\operatorname*{argmax}_{j,t} IG(\\mathbf{X}, S_{j,t})$ ist kleiner als ein festgelegter Threshold $\\epsilon$\n",
    "- Die Anzahl Beobachtungen in einem Node ist kleiner als ein festgelegter Threshold $m$\n",
    "- Jeder Leaf-Node muss mindestens eine Beobachtung haben.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bf2f6e3c2129374bc5bf9b11cd73fbab",
     "grade": false,
     "grade_id": "aufgabe2intro4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Notation\n",
    "\n",
    "- $n$: Anzahl Beobachtungen in einem Datensatz\n",
    "- $k$: Anzahl Features in einem Datensatz\n",
    "- $x^{(i)}_j$: Wert von Feature $j$ von Beobachtung $\\mathbf{x}^{(i)}$\n",
    "- $S_{j,t}$: Split-Kriterium. Dieses splittet entlang von Feature $j$ mit Threshold $t$. Beobachtungen mit $x_j<t$ gehen nach links, Beobachtungen mit $x_j \\ge t$ nach rechts.\n",
    "- $t$: Threshold für Feature-Split $\\in (-\\infty , +\\infty)$\n",
    "- $j$: Feature Index $\\in [0, k-1]$\n",
    "- $p$: Anteil positive Beobachtungen / Wahrscheinlichkeit dass eine Beobachtung positiv ($y=1$) ist $\\in [0, 1]$.\n",
    "- $y$: Label einer Beobachtung $\\in \\{0, 1\\}$\n",
    "- $\\mathbf{X}$: Ein Datensatz. Alle Datenpunkte / Beobachtungen **von einem bestimmten** Node (ausser beim Root-Node sind es also nicht alle Datenpunkte).\n",
    "- $IG(\\mathbf{X}, S_{j,t})$: Information Gain von $\\mathbf{X}$, falls man mit $S_{j,t}$ splittet.\n",
    "- $Q(\\mathbf{X})$: Die Impurity von einem Datensatz $\\mathbf{X}$.\n",
    "- $H(p)$ Die Entropie von $p$.\n",
    "- $|\\mathbf{X}|$ die Anzahl Beobachtungen in $\\mathbf{X}$.\n",
    "- $|\\mathbf{X}_l|$ die Anzahl Beobachtungen im linken Child-Node nach einem Split von $\\mathbf{X}$ (Beobachtungen mit $x_j<t$)\n",
    "- $|\\mathbf{X}_r|$ die Anzahl Beobachtungen im rechten Child-Node nach einem Split von $\\mathbf{X}$ (Beobachtungen mit $x_j \\ge t$)\n",
    "- $\\log_2(x)$: Logarithmus von $x$ zur Basis $2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a9bd506f8feb795a63446a1d0542ed9",
     "grade": false,
     "grade_id": "task2a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Aufbabe 2a\n",
    "\n",
    "Vervollständigen Sie die folgenden Klassen und Funktionen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4430a837c9256e9971a9db8720dd8ac6",
     "grade": true,
     "grade_id": "answer2a",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def binary_entropy(p: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Calculates the binary entropy over an array of positive proportions\n",
    "    Args:\n",
    "        p: (z,) 1-dimensional array with z elements, \n",
    "            each element denotes the proportion of positive samples\n",
    "    Returns:\n",
    "        (z,) the binary entropy of each proportion\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "class BinarySplitOptimizer:\n",
    "    \"\"\"Finds the best possible binary split of a dataset X, given a specific binary impurity function Q.\"\"\"\n",
    "    \n",
    "    def __init__(self, impurity: Callable[np.ndarray, np.ndarray]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            impurity: A function/callable that calculates the impurity given probabilities.\n",
    "                takes as input a 1-D array of k probabilities (z, )\n",
    "                returns z impurity values  (z, )\n",
    "        \"\"\"\n",
    "        self.impurity = impurity\n",
    "    \n",
    "    def find_optimal_split(self, X: np.ndarray, y: np.ndarray) -> (int, float, float):\n",
    "        \"\"\"\n",
    "        Finds the best split in X to minimize the impurity Q of the child-nodes.\n",
    "\n",
    "        Args: \n",
    "            X (n, k): Input features, where n is the number of samples and k is the number of features.\n",
    "            y (n, ): Target values.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple(j, t, impurity)\n",
    "            \n",
    "                j: The id of the feature 'j' to split, in  [0, k-1]\n",
    "                t: the threshold 't' of the feature to split\n",
    "                impurity: the impurity value\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def find_optimal_threshold(self, x: np.ndarray, y: np.ndarray) -> (float, float):\n",
    "        \"\"\"Find the threshold 't' that minimizes the impurity Q for a given feature vector x.\n",
    "\n",
    "        Args:\n",
    "            x: (n, ) The value of a specific feature for each of n data points\n",
    "            y: (n, ) The target / class label for each of n data points\n",
    "\n",
    "        Returns:\n",
    "            Tuple(t, impurity)\n",
    "            Threshold 't' that minimizes the impurity.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "45db79bffcacab93edc6b181183d11c2",
     "grade": false,
     "grade_id": "task2b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Aufgabe 2b\n",
    "\n",
    "Die folgende Zelle enthält verschiedene Tests die Ihre Implementation prüfen. Sorgen Sie dafür, dass die folgenden Tests erfolgreich sind. Stellen Sie sicher, dass die Input-Shapes der Methoden die Sie implementieren den Doc-Strings entsprechen.\n",
    "\n",
    "**Achtung: Die Tests decken nicht alles ab. Sie können also nicht davon ausegehen, dass Ihre Implementation korrekt ist sobald die Tests erfolgreich sind.**\n",
    "\n",
    "Es ist grundsätzlich ihre Aufgabe, die Implementation genau zu prüfen. Sie können dazu weitere Zellen mit eigenen Tests einfügen. Sie können jedoch die folgende Zelle nicht ändern. Diese wird nach Abgabe wieder überschrieben, sodass die von mir definierten Tests ausgeführt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "836d5be357b5fbffce2505d6c84d66e8",
     "grade": true,
     "grade_id": "answer2b",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def print_result(test_name, passed, expected, actual):\n",
    "    status = \"Passed\" if passed else \"Failed\"\n",
    "    print(f\"{status} test: {test_name}\")\n",
    "    print(f\"----> Expected: {expected}\")\n",
    "    print(f\"----> Actual: {actual}\")\n",
    "\n",
    "\n",
    "def run_test_binary_entropy():\n",
    "    probabilities = np.array([0.5, 1.0, 0.0])\n",
    "    expected = np.array([1.0, 0.0, 0.0])\n",
    "    actual = binary_entropy(probabilities)\n",
    "\n",
    "    try:\n",
    "        np.testing.assert_almost_equal(actual, expected, decimal=2)\n",
    "        print_result(\"run_test_binary_entropy_calculator\", True, expected, actual)\n",
    "    except AssertionError:\n",
    "        print_result(\"run_test_binary_entropy_calculator\", False, expected, actual)\n",
    "\n",
    "    \n",
    "def run_test_impurity_optimizer():\n",
    "    x = np.array([1, 2, 3, 4, 5])  # Feature values\n",
    "    y = np.array([0, 0, 1, 1, 1])  # Binary classification labels\n",
    "    expected_threshold = 2.5  # All thresholds between 2 and 3 are identical, we choose their mean\n",
    "    expected_impurity = 0.0  # This is the expected value if binary entropy is the measure\n",
    "\n",
    "    impurity_optimizer = BinarySplitOptimizer(binary_entropy)\n",
    "    actual_threshold, actual_impurity = impurity_optimizer.find_optimal_threshold(x, y)\n",
    "\n",
    "    try:\n",
    "        np.testing.assert_almost_equal(expected_threshold, actual_threshold)\n",
    "        np.testing.assert_almost_equal(expected_impurity, actual_impurity)\n",
    "        print_result(\n",
    "            \"run_test_impurity_optimizer\", True, \n",
    "            (expected_threshold, expected_impurity),\n",
    "            (actual_threshold, actual_impurity))\n",
    "    except AssertionError as e:\n",
    "        print_result(\n",
    "            \"run_test_impurity_optimizer\", False,\n",
    "            (expected_threshold, expected_impurity),\n",
    "            (actual_threshold, actual_impurity))\n",
    "\n",
    "\n",
    "def run_test_impurity_splitter():\n",
    "    \n",
    "    X = np.array([\n",
    "        [1, 2],\n",
    "        [9, 3],\n",
    "        [3, 10],\n",
    "        [4, 18],\n",
    "        [5, 20]\n",
    "    ])\n",
    "    \n",
    "    y = np.array([0, 0, 1, 1, 1])  # Binary classification labels\n",
    "    expected_feature_id = 1  # Assuming the second feature is the best for splitting\n",
    "    expected_threshold = 6.5  # Assuming the best split is between 3 and 10 for the second feature\n",
    "    expected_impurity = 0.0  # This is the expected value if binary entropy is the measure\n",
    "\n",
    "    binary_split_optimizer = BinarySplitOptimizer(binary_entropy)\n",
    "    actual_feature_id, actual_threshold, actual_impurity = binary_split_optimizer.find_optimal_split(X, y)\n",
    "\n",
    "    try:\n",
    "        np.testing.assert_almost_equal(expected_threshold, actual_threshold)\n",
    "        np.testing.assert_almost_equal(expected_impurity , actual_impurity)\n",
    "        np.testing.assert_equal(expected_feature_id, actual_feature_id)\n",
    "        print_result(\n",
    "            \"run_test_impurity_splitter\", True,\n",
    "            (expected_feature_id, expected_threshold, expected_impurity),\n",
    "            (actual_feature_id, actual_threshold, actual_impurity))\n",
    "    except AssertionError as e:\n",
    "        print_result(\n",
    "            \"run_test_impurity_splitter\", False, \n",
    "            (expected_feature_id, expected_threshold, expected_impurity),\n",
    "            (actual_feature_id, actual_threshold, actual_impurity))\n",
    "\n",
    "\n",
    "for test in [run_test_binary_entropy, run_test_impurity_optimizer, run_test_impurity_splitter]:\n",
    "    try:\n",
    "        test()\n",
    "    except Exception as e:\n",
    "        print(f\"Error during testing - test: {test} error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "94d3f6bc124e32db0cd952c2738db6f4",
     "grade": false,
     "grade_id": "task2c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Aufgabe 2c\n",
    "Jetzt werden Sie den `BinaryDecisionTreeClassifier` implementieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f12f29a918f30aeefb8fcb5839c9ff4c",
     "grade": true,
     "grade_id": "answer2c",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Self, Callable\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# Helper classes that can be used to construct the decision tree\n",
    "@dataclass\n",
    "class LeafNode:\n",
    "    value: float # value of leaf node (positive class proportion)\n",
    "    depth: int # depth of the node\n",
    "    is_leaf_node: bool = True\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TreeNode:\n",
    "    feature_index: int # feature on which to split \n",
    "    threshold: float # threshold on which to split \n",
    "    depth: int # depth of the node\n",
    "    left: Self | LeafNode # the left child node\n",
    "    right: Self | LeafNode # the right child node\n",
    "    is_leaf_node: bool = False   \n",
    "\n",
    "\n",
    "class BinaryDecisionTreeClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"Binary Decision Tree Classifier\n",
    "    \n",
    "    Args:\n",
    "    -----\n",
    "        max_depth: max depth of the decision tree, \n",
    "            if max depth is reached a leaf node is created\n",
    "        min_information_gain_to_split: minimum information gain required to split a node, \n",
    "            otherwise a leaf node is created\n",
    "        min_samples_in_node_for_split: minimum number of samples required to split a node,\n",
    "            otherwise a leaf node is created\n",
    "        p_feature_sampling: proportion of features to consider at each node (random subsample), (0, 1]\n",
    "        impurity: function / callable to calculate binary impurity\n",
    "        random_seed: ensure reproducibility for random steps\n",
    "        verbose: bool, whether to print log messages (optional)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        max_depth: int | None = None,\n",
    "        min_information_gain_to_split = 0.0,\n",
    "        min_samples_in_node_for_split: int = 2,\n",
    "        p_feature_sampling: float = 1.0,\n",
    "        impurity: Callable[np.ndarray, np.ndarray]=binary_entropy,\n",
    "        random_seed: int=123,\n",
    "        verbose: bool = False):\n",
    "\n",
    "        self.max_depth = max_depth\n",
    "        self.min_information_gain_to_split = min_information_gain_to_split\n",
    "        self.min_samples_in_node_for_split = min_samples_in_node_for_split\n",
    "        self.p_feature_sampling = p_feature_sampling\n",
    "        self.impurity = impurity\n",
    "        self.verbose = verbose\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "        self._splitter = BinarySplitOptimizer(self.impurity)\n",
    "        self._rng = np.random.default_rng(random_seed)\n",
    "        \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> Self:\n",
    "        \"\"\"Fit Decision Tree\n",
    "\n",
    "        Args:\n",
    "        -----\n",
    "            X: (n, k)\n",
    "            y: (n, )\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "            self\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Return most likely class per sample\n",
    "\n",
    "        Args:\n",
    "        -----\n",
    "            X: (n, k)\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "            (n, )\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Return probability of being the positive class per sample.\n",
    "\n",
    "        Args:\n",
    "        -----\n",
    "            X: (n, k)\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "            (n, )\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def score(self, X: np.ndarray, y: np.ndarray) -> float:\n",
    "        \"\"\"Calculate Accuracy\n",
    "\n",
    "        Args:\n",
    "        -----\n",
    "            X: (n, k)\n",
    "            y: (n, )\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "            accuracy (float)\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    # any helper methods\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5e6dd7e81135040a2bde4259e7e59380",
     "grade": false,
     "grade_id": "task2d_a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Aufgabe 2d\n",
    "\n",
    "Nun überprüfen Sie grafisch ob Ihre Implementation funktioniert.\n",
    "\n",
    "Fitten Sie dazu jeweils 2 Modelle auf jedem Beispiel-Datensatz.\n",
    "\n",
    "Für jeden Modell-Fit und Datensatz: Zeigen Sie den Datensatz (Plot) und plotten Sie die _Decision Regions_ der Modelle. Verwenden Sie [mlxtend.plotting.plot_decision_regions](https://rasbt.github.io/mlxtend/api_subpackages/mlxtend.plotting/#plot_decision_regions).\n",
    "\n",
    "Berechnen Sie jeweils die Accuracy mit `score(X, y)` und zeigen Sie diese oberhalb von den Decision-Region-Plots. Z.B mit: \n",
    "\n",
    "```\n",
    "accuracy = dt.score(X, y)\n",
    "_ = ax.set_title(f\"Accuracy: {accuracy:.2f}\")\n",
    "```\n",
    "\n",
    "Sie sollen also pro Datensatz jeweils 3 Plots zeigen (Daten, Decision-Region Modell 1, Decision-Region Modell 2).\n",
    "\n",
    "Verwenden Sie folgende Parameter für Modell 1:\n",
    "\n",
    "- `max_depth=3`\n",
    "- `min_information_gain_to_split=0.0`\n",
    "- `min_samples_in_node_for_split=3`\n",
    "- `p_feature_sampling=1.0`\n",
    "\n",
    "\n",
    "Verwenden Sie folgende Parameter für Modell 2:\n",
    "\n",
    "- `max_depth=10`\n",
    "- `min_information_gain_to_split=0.0`\n",
    "- `min_samples_in_node_for_split=0`\n",
    "- `p_feature_sampling=1.0`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5af1797a21fc0631383f84516cc73cfe",
     "grade": true,
     "grade_id": "answer2d_a",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification, make_blobs, make_moons\n",
    "import mlxtend\n",
    "import seaborn as sns\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_ds1():\n",
    "    # Number of observations in each class\n",
    "    num_obs = 50\n",
    "    rng = np.random.default_rng(123)\n",
    "\n",
    "    # Generating x1 and x2\n",
    "    x1 = np.linspace(-4, 4, num_obs).reshape(-1, 1)\n",
    "    x2 = np.linspace(-4, 4, num_obs).reshape(-1, 1)\n",
    "\n",
    "    # Initial binary classification, without noise\n",
    "    X = np.hstack([x1, x2])\n",
    "    X = np.vstack([X, X])  # Doubling for both classes\n",
    "    class_perturbation = np.hstack([1 + rng.standard_normal(num_obs) * 0.2, -1 + rng.standard_normal(num_obs) * 0.2])\n",
    "    X[:, 0] += class_perturbation  # Adding noise to the x1 component\n",
    "    \n",
    "    # Generating labels\n",
    "    y = np.hstack([np.repeat(0, num_obs), np.repeat(1, num_obs)])\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def generate_ds2():\n",
    "    X, y = make_classification(\n",
    "        n_samples=100, n_features=2, n_informative=1, n_redundant=0, n_repeated=0, \n",
    "        n_classes=2, n_clusters_per_class=1, weights=None, flip_y=0, class_sep=2.0, \n",
    "        hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=123)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def generate_ds3():\n",
    "    X, y = make_moons(noise=0.3, random_state=0)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def generate_ds4():\n",
    "    # Defining centers for the clusters\n",
    "    centers = [(-3, -3), (3, 3)]\n",
    "    cluster_std = 0.5  # Standard deviation of the clusters\n",
    "\n",
    "    # Generating the dataset\n",
    "    X, y = make_blobs(n_samples=400, centers=centers, cluster_std=cluster_std, n_features=2, random_state=123)\n",
    "    y = y % 2\n",
    "    \n",
    "    # add additional points\n",
    "    X_add = np.array([\n",
    "        [-3, 4],\n",
    "        [0, -2],\n",
    "        [4, -2],\n",
    "        [-3, 2]\n",
    "    ]).reshape(-1, 2)\n",
    "    y_add = np.array([1, 1, 0, 0]).reshape(-1)\n",
    "    \n",
    "    X = np.vstack([X, X_add])\n",
    "    y = np.hstack([y, y_add])\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def generate_ds5():\n",
    "    grid_size = 5\n",
    "    rng = np.random.default_rng(seed=123)\n",
    "    # Create grid points\n",
    "    X = [(x, y) for x in range(grid_size) for y in range(grid_size)]\n",
    "    # Assign classes\n",
    "    y = [(x + y) % 2 for x, y in X]\n",
    "    #X = [(x - (grid_size % 2), y - (grid_size % 2)) for x, y in X]\n",
    "    X = [(x + rng.uniform(-0.1, 0.1), y + rng.uniform(-0.1, 0.1)) for x, y in X]\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "# iterating over the toy datasets\n",
    "for i, (X, y) in enumerate([generate_ds1(), generate_ds2(), generate_ds3(), generate_ds4(), generate_ds5()]):\n",
    "    \n",
    "    # Plot the dataset\n",
    "    fig, ax = plt.subplots(figsize=(12, 4), ncols=3)\n",
    "    _ = sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=y, ax=ax[0]).set(title=f\"Dataset {i + 1}\")\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "faba29ead2b288cd6f3dd80dfa54f2aa",
     "grade": false,
     "grade_id": "task2d_b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Erläutern Sie die Ergebnisse von jedem Datensatz. Argumentieren Sie klar und nachvollziehbar indem Sie auf die Grafiken verweisen.\n",
    "- Diskutieren Sie kurz die Güte der Modellierung. Welches Modell (1 oder 2) gefällt ihnen besser und warum?\n",
    "- Falls Unterschiede zwischen den Modellen sichtbar sind: Erklären Sie diese aufgrund der Hyperparameter und reflektieren Sie ob ihre Implementation wie erwartet funktioniert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3cfcd2801dbb52c8c22e263358ff5c46",
     "grade": true,
     "grade_id": "answer2d_b",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9d16c55ff7c95893803513c9c1b74d6d",
     "grade": false,
     "grade_id": "task2e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Aufgabe 2e\n",
    "Nun implementieren Sie den `BinaryRandomForestClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c9242a1bd59a2949bfa12c923e43eea",
     "grade": true,
     "grade_id": "answer2e",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Self\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.base import ClassifierMixin, BaseEstimator\n",
    "\n",
    "\n",
    "class BinaryRandomForestClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"Binary Random Forest Classifier\n",
    "    \n",
    "    Args:\n",
    "    -----\n",
    "        num_trees: the number of decision trees to fit\n",
    "        max_depth: max depth of the decision tree, \n",
    "            if max depth is reached a leaf node is created\n",
    "        min_information_gain_to_split: minimum information gain required to split a node, \n",
    "            otherwise a leaf node is created\n",
    "        min_samples_in_node_for_split: minimum number of samples required to split a node,\n",
    "            otherwise a leaf node is created\n",
    "        p_feature_sampling: proportion of features to consider at each node (random subsample), (0, 1]\n",
    "        impurity: function / callable to calculate binary impurity\n",
    "        random_seed: ensure reproducibility for random operations\n",
    "        verbose: bool, whether to print log messages (optional)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_trees: int = 10,\n",
    "        max_depth: int | None = None,\n",
    "        min_information_gain_to_split: float = 0.0,\n",
    "        min_samples_in_node_for_split: int = 2,\n",
    "        p_feature_sampling: float = 1.0,\n",
    "        verbose: bool=False,\n",
    "        random_seed: int=123\n",
    "    ):\n",
    "        self.num_trees = num_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_in_node_for_split = min_samples_in_node_for_split\n",
    "        self.min_information_gain_to_split = min_information_gain_to_split\n",
    "        self.p_feature_sampling = p_feature_sampling\n",
    "        self.random_seed = random_seed\n",
    "        self.verbose = verbose\n",
    "        self._trees = []\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> Self:\n",
    "        \"\"\"Fit the model\n",
    "\n",
    "        Args:\n",
    "        -----\n",
    "            X: (n, k)\n",
    "            y: (n, )\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "            self\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Return most likely class per sample\n",
    "\n",
    "        Args:\n",
    "        -----\n",
    "            X: (n, k)\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "            (n, )\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Return probability of being the positive class per sample.\n",
    "\n",
    "        Args:\n",
    "        -----\n",
    "            X: (n, k)\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "            (n, )\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def score(self, X: np.ndarray, y: np.ndarray) -> float:\n",
    "        \"\"\"Calculate Accuracy\n",
    "\n",
    "        Args:\n",
    "        -----\n",
    "            X: (n, k)\n",
    "            y: (n, )\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "            a\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    # any helper methods if needed\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a0924dbecccffd12a7a95e3865982cba",
     "grade": false,
     "grade_id": "task2f_a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Aufgabe 2f\n",
    "\n",
    "Nun testen Sie den `BinaryRandomForestClassifier`. Verwenden Sie denselben Ansatz wie aus Aufgabe 2d. Trainieren Sie pro Datensatz jeweils zwei Modelle mit folgenden Parametern:\n",
    "\n",
    "Verwenden Sie folgende Parameter für Modell 1:\n",
    "\n",
    "- `num_trees=5`\n",
    "- `max_depth=10`\n",
    "- `min_information_gain_to_split=0.0`\n",
    "- `min_samples_in_node_for_split=0`\n",
    "- `p_feature_sampling=1.0`\n",
    "\n",
    "\n",
    "\n",
    "Verwenden Sie folgende Parameter für Modell 2:\n",
    "\n",
    "- `num_trees=30`\n",
    "- `max_depth=10`\n",
    "- `min_information_gain_to_split=0.0`\n",
    "- `min_samples_in_node_for_split=0`\n",
    "- `p_feature_sampling=1.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7fb4ee7d4aa11f009801f1683376d99d",
     "grade": true,
     "grade_id": "answer2f_a",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# iterating over the toy datasets\n",
    "for i, (X, y) in enumerate([generate_ds1(), generate_ds2(), generate_ds3()]):\n",
    "    \n",
    "    # Plot the dataset\n",
    "    fig, ax = plt.subplots(figsize=(12, 4), ncols=3)\n",
    "    _ = sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=y, ax=ax[0]).set(title=f\"Dataset {i + 1}\")\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e7b5183ab372490267cdadf3fa4c87ba",
     "grade": false,
     "grade_id": "task2f_b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Erläutern Sie die Ergebnisse von jedem Datensatz. Argumentieren Sie klar und nachvollziehbar indem Sie auf die Grafiken verweisen.\n",
    "- Diskutieren Sie die Güte der Modellierung. Welches Modell (1 oder 2) gefällt ihnen besser und warum?\n",
    "- Falls Unterschiede zwischen den Modellen sichtbar sind: Erklären Sie diese aufgrund der Hyperparameter und reflektieren Sie ob ihre Implementation wie erwartet funktioniert.\n",
    "- Erwähnen und diskutieren Sie Unterschiede zu den Tests aus 2d. Inwiefern sieht man, dass es sich hier um einen RandomForest handelt?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f208288a160e9d57739ee5f19da1c16f",
     "grade": true,
     "grade_id": "answer2f_b",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "391da7eb9514c847b4ba37cf6c88e959",
     "grade": false,
     "grade_id": "aufgabe3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Aufgabe 3 (12 Punkte)\n",
    "\n",
    "In dieser Aufgabe modellieren Sie die Hotel-Daten und versuchen ein möglichst gutes Modell zu finden.\n",
    "\n",
    "Hinweis: Sollte es Ihnen nicht gelungen sein die Modelle zu implementieren können Sie [sklearn.ensemble.RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) und [sklearn.tree.DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) verwenden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d89b84dffc6d6302632ab7e57cd3fc3f",
     "grade": false,
     "grade_id": "task3a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Aufgabe 3a\n",
    "\n",
    "Trainieren Sie verschiedene Modelle der Klassen `BinaryRandomForestClassifier` und `BinaryDecisionTreeClassifier` auf dem Datensatz `hotel_train.csv` um `IstStorniert` vorherzusagen.\n",
    "\n",
    "Vergleichen Sie die Modelle und finden Sie die beste Konfiguration. Verwenden Sie Kreuzvalidierung.\n",
    "\n",
    "Berechnen Sie den Score vom besten Modell auf dem Trainings-Datensatz und auf dem Validierungs-Datensatz `hotel_validation.csv` und geben Sie diese aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2fd6e7f5dfb9f85d8be3b013cb39d91",
     "grade": true,
     "grade_id": "antwort3a",
     "locked": false,
     "points": 8,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fb2b17ecb84b50ad31d6665473db9fe0",
     "grade": false,
     "grade_id": "task3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Aufgabe 3b\n",
    "\n",
    "Interpretieren Sie das Ergebnis:\n",
    "\n",
    "- Welche Modell-Varianten haben Sie verglichen? Begründen Sie kurz warum Sie welche Parameter wie variiert haben.\n",
    "- Vergleichen und interpretieren Sie Scores auf Trainings- und Validation-Datensatz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "912b67978d82959430bf6b29e36c8692",
     "grade": true,
     "grade_id": "answer3b",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "097d7c1f1d5ffb11bcbbc277f78b14f4",
     "grade": false,
     "grade_id": "task3c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Aufgabe 3c\n",
    "\n",
    "Beantworten Sie folgende Fragen:\n",
    "\n",
    "- Mika fragt Sie ob es hilfreich wäre mehr Trainingsdaten zu sammeln (was viel Zeit und Geld kosten würde). Kann man diese Frage beantworten? Falls ja, wie würden Sie vorgehen?\n",
    "- Mika muss eine Präsentation für das Hotel-Management vorbereiten und die Ergebnisse, sowie Empfehlungen vorstellen. Mika bittet Sie um Rat. Wie könnte das Management dieses Modell nun gewinnbringend einsetzen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b786be52910cd2febc19098a4e900d94",
     "grade": true,
     "grade_id": "answer3c",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47a2590878cab508e93a9454ae72e4ce",
     "grade": false,
     "grade_id": "aufgabe4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Aufgabe 4 (Bonusaufgabe, 5 Punkte) Competition\n",
    "\n",
    "In dieser Aufgabe geht es darum auf einem Testset Vorhersagen zu generieren die möglichst akkurat sind. Sie dürfen dazu das Modell aus Aufgabe 3 verwenden oder ein komplett neues Modell erstellen. Sie dürfen dabei alle Methoden aus `sklearn` verwenden (auch andere Modelle und Algorithmen).\n",
    "\n",
    "Sie müssen die Vorhersagen abspeichern und mit dem finalen Commit abgeben. \n",
    "\n",
    "Ihre Vorhersagen werden dann beurteilt und mit denjenigen Ihrer Kolleginnen und Kollegen verglichen.\n",
    "\n",
    "Die besten kriegen die Bonuspunke.\n",
    "\n",
    "Beachten Sie die maximale Laufzeit vom Notebook von 30 Minuten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "682ff87c8ab0e34508dc140d720893c3",
     "grade": false,
     "grade_id": "task4a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Aufgabe 4a\n",
    "\n",
    "Lesen Sie das File `hotel_test.csv` ein und generieren Sie die Vorhersagen.  Speichern Sie diese in das File `hotel_test_predictions.csv`. \n",
    "\n",
    "Definieren Sie im Code die Variable `my_leaderboard_name`. Dies ist Ihr Pseudonym für die öffentliche Anzeige von ihrem Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fde91aaf046bd2f84f49cacc837e04c8",
     "grade": true,
     "grade_id": "answer4a",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Read the test dataset\n",
    "df_test = pd.read_csv(\"hotel_test.csv\")\n",
    "\n",
    "# TODO: Change `my_leaderboard_name` to a name of your liking\n",
    "my_leaderboard_name = 'dummy'\n",
    "\n",
    "# TODO: these are dummy predictions to demonstrate how the output should look like.\n",
    "# replace them with better predictions!\n",
    "\n",
    "fname_predictions = \"hotel_test_predictions.csv\"\n",
    "y_hat = np.array([0 for _ in range(df_test.shape[0])]).reshape(-1)\n",
    "df_test_predictions = pd.DataFrame({\"IstStorniert\": y_hat})                                             \n",
    "df_test_predictions.to_csv(fname_predictions, index=False)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5a97b2200bcd1d9fa07be0d44c5e148d",
     "grade": false,
     "grade_id": "task4a_eval_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Der folgende Code soll / kann nicht verändert werden. Dieser liest ihre Vorhersagen ein, evaluiert diese, und schreibt das Resultat in ein File."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c58d01c33df16996253cf01feb93cb2",
     "grade": false,
     "grade_id": "evaluate_task4a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ensure that `hotel_test_predictions.csv` exists!\n",
    "if Path(fname_predictions).exists():\n",
    "    has_test_predictions = True\n",
    "    print(f\"Reading Predictions from {fname_predictions}\")\n",
    "    df_test_predictions = pd.read_csv(fname_predictions, index_col=False)\n",
    "    y_hat = df_test_predictions[[\"IstStorniert\"]].to_numpy().reshape(-1)\n",
    "else:\n",
    "    has_test_predictions = False\n",
    "    print(f\"File {fname_predictions} not found\")\n",
    "\n",
    "# reads the y_true for the test dataset (not available to you!)\n",
    "path_df_test_solutions = \"/home/jovyan/work/data/hotel_bookings/hotel_test_solution.csv\"\n",
    "\n",
    "if Path(path_df_test_solutions).exists() & has_test_predictions:\n",
    "    print(f\"File {path_df_test_solutions} found\")\n",
    "    df_test_true = pd.read_csv(path_df_test_solutions, index_col=False)\n",
    "    y_true = df_test_true[[\"IstStorniert\"]].to_numpy().reshape(-1)\n",
    "    print(f\"Test Accuracy: {accuracy_score(y_true, y_hat)}\")\n",
    "\n",
    "    with open(\"test_accuracy.txt\", \"w\") as f:\n",
    "        _ = f.write(f\"{accuracy_score(y_true, y_hat):.5f},{my_leaderboard_name}\")\n",
    "else:\n",
    "    print(f\"File {path_df_test_solutions} not found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
